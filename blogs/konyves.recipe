import string, re
from calibre.web.feeds.recipes import BasicNewsRecipe
from calibre.constants import config_dir, CONFIG_DIR_MODE
import os, os.path, urllib
from hashlib import md5

class KonyvesBlogHu(BasicNewsRecipe):
    __author__              = 'Zsolt Botykai'
    title                   = u'Könyves Blog'
    description             = u'Konyves.blog.hu'
    oldest_article          = 10000
    max_articles_per_feed   = 10000
    reverse_article_order   = True
    language                = 'hu'
    remove_javascript       = True
    remove_empty_feeds      = True
    no_stylesheets          = True
    feeds                   = [(u'Könyves Blog', u'http://konyves.blog.hu/rss')]
    remove_javascript       = True
    use_embedded_content    = False
    remove_tags = [
                       dict(name='div', attrs={'id':['fb-root']}) ,
                       dict(name='img', attrs={'style':['position: absolute;top:-10px;left:-10px;']}) ,
                       dict(name='div', attrs={'class':['blh_share_fblike', \
                                                        'blh_share_cont', \
                                                        'blh-billboard-ad', \
                                                        'commentsBg', \
                                                        'clear', \
                                                        'related']}) ,
                       dict(name='a', attrs={'name':['trackbacks','pingbacks',\
                                                     'feedbacks','comments']}),
                       dict(name='h3', attrs={'class':['comment comment-tracback-url','comments']})  
                  ]



    preprocess_regexps      = [
        (re.compile(r'<div class="related".*?</body>', re.DOTALL|re.IGNORECASE),
         lambda match: '</body>'),
        (re.compile(r'<body.*?<div class="post', re.DOTALL|re.IGNORECASE),
         lambda match: '<body><div class="post'),
        (re.compile(r'<p align="left"'), lambda m: '<p'),
        (re.compile(r'<noscript.+?noscript>', re.DOTALL|re.IGNORECASE), lambda m: ''),
        (re.compile(r'<img style="position: absolute;top:-10px.+?>', re.DOTALL|re.IGNORECASE), lambda m: ''),
        (re.compile(r'<p>( |&nbsp;)*?</p>', re.DOTALL|re.IGNORECASE), lambda match: ''),
        (re.compile(r'<span class="date"', re.DOTALL|re.IGNORECASE), 
         lambda match: '<span class="date" style="font-size: 80%;"'),
        (re.compile(r'<span class="author"', re.DOTALL|re.IGNORECASE), 
         lambda match: '<span class="author" style="font-size: 80%;"'),
        (re.compile(r'<a href="http:[^:]+scribd.com.*?</a>', re.DOTALL|re.IGNORECASE), 
         lambda match: 'Sajnos itt egy megjeleníthetetlen beágyazott dokumentum következne :-(<br />'),
    ]

    extra_css = '''
                    body { background-color: white; color: black }
                '''

    masthead_url='http://m.blog.hu/ko/konyves/skins/ujkonyves_mod3/img/header.gif'

    def get_cover_url(self):
        return 'http://m.blog.hu/ko/konyves/skins/ujkonyves_mod3/img/header.gif'

    def preprocess_html(self, soup):
        for tagz in soup.findAll('h3', attrs={'class':'tags'}):
            for taglink in tagz.findAll('a'):
                if taglink.string is not None:
                   tstr = taglink.string + ','
                   taglink.replaceWith(tstr)
        
        for spanlink in soup.findAll('span', attrs={'class':'author'}):
            for authlink in spanlink.findAll('a'):
                if authlink.string is not None:
                   tstr = authlink.string
                   authlink.replaceWith(tstr)

        return soup

    # As seen here: http://www.mobileread.com/forums/showpost.php?p=1295505&postcount=10
    def parse_feeds(self):
        recipe_dir = os.path.join(config_dir,'recipes')
        hash_dir = os.path.join(recipe_dir,'recipe_storage')
        feed_dir = os.path.join(hash_dir,self.title.encode('utf-8').replace('/',':'))
        if not os.path.isdir(feed_dir):
            os.makedirs(feed_dir,mode=CONFIG_DIR_MODE)

        feeds = BasicNewsRecipe.parse_feeds(self)

        for feed in feeds:
            feed_hash = urllib.quote(feed.title.encode('utf-8'),safe='')
            feed_fn = os.path.join(feed_dir,feed_hash)

            past_items = set()
            if os.path.exists(feed_fn):
               with file(feed_fn) as f:
                   for h in f:
                       past_items.add(h.strip())
                      
            cur_items = set()
            for article in feed.articles[:]:
                item_hash = md5()
                if article.content: item_hash.update(article.content.encode('utf-8'))
                if article.summary: item_hash.update(article.summary.encode('utf-8'))
                item_hash = item_hash.hexdigest()
                if article.url:
                    item_hash = article.url + ':' + item_hash
                cur_items.add(item_hash)
                if item_hash in past_items:
                    feed.articles.remove(article)
            with file(feed_fn,'w') as f:
                for h in cur_items:
                    f.write(h+'\n')

        remove = [f for f in feeds if len(f) == 0 and
                self.remove_empty_feeds]
        for f in remove:
            feeds.remove(f)

        return feeds

# Release: v20110325
